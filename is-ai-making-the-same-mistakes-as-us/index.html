<!DOCTYPE html>
<html lang="en-US" />
<head>
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

    <title>Is AI making the same mistakes as us? &middot; </title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="https://mkraft89.github.io/favicon.ico" />
    <link rel="canonical" href="https://mkraft89.github.io/is-ai-making-the-same-mistakes-as-us/" />

     <meta name="description" content="Is AI making the same mistakes as us? I watched the Netflix documentary CodedBias last weekend. And it raised some rather good points about AI development. For " /> 

     
    
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image" content="https://mkraft89.github.io/image/niv-singer-banksy.jpg"/>
    
 
    <meta name="twitter:title" content="Is AI making the same mistakes as us?"/>
    <meta name="twitter:description" content="Is AI making the same mistakes as us? I watched the Netflix documentary CodedBias last weekend. And it raised some rather good points about AI development. For "/>
    <meta name="twitter:url" content="https://mkraft89.github.io/is-ai-making-the-same-mistakes-as-us/" />
    <meta name="twitter:site" content="@"/>

    <meta property="og:site_name" content="" />
    <meta property="og:title" content="Is AI making the same mistakes as us? &middot; Matthias Kraft" />
    <meta property="og:url" content="https://mkraft89.github.io/is-ai-making-the-same-mistakes-as-us/" />
    

    <meta property="og:type" content="article" />
    <meta property="og:description" content="Is AI making the same mistakes as us? I watched the Netflix documentary CodedBias last weekend. And it raised some rather good points about AI development. For " />

    <meta property="article:published_time" content="2021-04-23T00:00:00Z" />
    <meta property="article:tag" content="safeai" /><meta property="article:tag" content="LakeraAI" />

    <meta property="og:image" content="https://mkraft89.github.io/image/niv-singer-banksy.jpg"/>



    <meta name="generator" content="Hugo 0.82.1" />

    <!-- Stylesheets -->
    <link rel="stylesheet" type="text/css" href="https://mkraft89.github.io/built/screen.css" /> 
    <link rel="stylesheet" type="text/css" href="https://mkraft89.github.io/css/casper-two.css" /> 
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" />
    

     

</head>


<body class="post-template">
  <div class="site-wrapper"> 

<header class="site-header outer">
  <div class="inner">
    <nav class="site-nav">
      <div class="site-nav-left">

        <ul class="nav" role="menu">
        
        
      </ul></div>

      <div class="site-nav-right">
        <div class="social-links">
                    

                    

                    <a class="social-link" href="https://github.com/mkraft89" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>

                    <a class="social-link" href="https://www.linkedin.com/in/matthias-kraft-5b1229a1" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 50 512 512"><path d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683 C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615 c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915 s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z" /></svg></a>

                    
        </div>  
            
      </div>

    </nav>  

  </div>
</header>


<main id="site-main" class="site-main outer" role="main">
  <div class="inner">
    
      <article class="post-full post"> 
    <header class="post-full-header">
        <section class="post-full-meta">
            <time class="post-full-meta-date" datetime="2021-04-23">23 April 2021</time>
                <span class="date-divider">/</span> <a href="https://mkraft89.github.iotags/safeai/">#safeai</a>&nbsp;<a href="https://mkraft89.github.iotags/lakeraai/">#LakeraAI</a>&nbsp;
        </section>
        <h1 class="post-full-title">Is AI making the same mistakes as us?</h1>
    </header>
    
    <figure class="post-full-image" style="background-image: url(https://mkraft89.github.io/image/niv-singer-banksy.jpg)">
    </figure>

    <section class="post-full-content">
        <div class="kg-card-markdown">
        <h1 id="is-ai-making-the-same-mistakes-as-us">Is AI making the same mistakes as us?</h1>
<p>I watched the Netflix documentary <a href="https://www.codedbias.com/">CodedBias</a> last weekend. And it raised some rather good points about AI development. For those of you who haven’t yet seen the film, it tells the story of a group of inspiring women fighting against the dark side of AI. The documentary feels like a natural follow-up to the film <a href="https://www.thesocialdilemma.com/">SocialDilemma</a>. And, if you were horrified by the practices uncovered in it, I strongly recommend you also watch <a href="https://www.codedbias.com/">CodedBias</a>!</p>
<p>Rather than exploring Terminator-style takeover scenarios by a super-intelligent AI, <a href="https://www.codedbias.com/">CodedBias</a> takes a hard look at the real problems created by AI technologies today. It does a great job at highlighting the issue of bias in AI, and how that adversely affects whole demographics. The point is most strikingly illustrated by the example of a recidivism algorithm <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">discriminating against Black defendants</a>. We don’t need to look very far either to find instances of bias in AI beyond those brought up in the documentary. Even Google Translate, which is a fairly innocent looking service for the public benefit, can exhibit <a href="https://twitter.com/DoraVargha/status/1373211762108076034?s=20">biases</a> (see image below). Ultimately, bias in AI is a real issue. And as the consumers and subjects of these algorithms, this should worry us all.</p>
<p><img src="/image/GoogleHungarianEnglishGenderBiasedTranslation.png" alt="Translate"><em>Example of AI bias in translating from a gender neutral language, Hungarian, to English.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></em></p>
<p>So, rightly, the documentary takes a look at the bigger picture of how these technologies are being used. Even if it was free of inherent bias, is AI-powered video surveillance really the way to go? Do we want to enable corporate powers to predict our behaviour with ever-increasing accuracy by giving them our data? These are questions that we, as a society, have to answer.</p>
<h1 id="is-developing-ai-worth-the-risk">Is developing AI worth the risk?</h1>
<p>Due to the risks outlined in <a href="https://www.codedbias.com/">CodedBias</a>, one might be left wondering – is using AI worth it? The answer is an emphatic YES. This might come as a surprise to those of you who have seen <a href="https://www.codedbias.com/">CodedBias</a>, since the documentary sacrifices this side of the discussion to achieve cohesive storytelling. In reality, the potential to do social good using AI is enormous. Even before we perfect self-driving cars, AI-based advanced driver-assistance systems will save human lives. AI advances in radiology will assist doctors in cancer diagnosis and allow the development of more personalised treatment plans. AI will speed up and improve drug discovery, giving us the chance to treat and cure more diseases. In agriculture, AI lets farmers monitor the health of their crops to an unprecedented level of accuracy, which enables more sustainable farming. And the list goes on.</p>
<h1 id="the-path-forward---how-to-ensure-unbiased-ai">The path forward - how to ensure unbiased AI?</h1>
<p>The question is, how can we reap the benefits of AI while simultaneously eliminating the downsides? To solve this problem, <a href="https://www.codedbias.com/">CodedBias</a> makes a case for the necessity of regulations. What we need is a sort of “FDA<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> for algorithms”<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. In a pledge, the makers of <a href="https://www.codedbias.com/">CodedBias</a> demand that:</p>
<p><!-- raw HTML omitted -->“&hellip; algorithmic systems be vetted for accuracy, bias, and non-discrimination, evaluated for harms and capacity for abuse, and subject to continuous scrutiny.”<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup><!-- raw HTML omitted --></p>
<p>This is a call that I fully support! When AI algorithms are used to assess our teachers or to determine our credit worthiness, when they impact human lives or society at any scale, we should expect them to be regulated. I am glad that efforts to create frameworks for compliance are already being developed by regulators in <a href="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device">healthcare</a>, <a href="https://www.easa.europa.eu/sites/default/files/dfu/easa_concept_paper_first_usable_guidance_for_level_1_machine_learning_applications_-_proposed_issue_01_1.pdf">aviation</a>, automotive, and other industries. Though I must say, I don’t envy those regulators because they are facing an incredibly tough job. If they make the proposed regulations too lax, society will lose as a result. If regulations are made too strict, they won’t allow innovation and, again, society will lose. And if they end up being so complex that only big players can follow them – you guessed it – society will lose. To walk this fine line of not too lax, not too strict and not too complex regulations, lawmakers would benefit in developing these through short, use-case driven projects involving companies of various sizes and researchers alike.</p>
<p>Of course, regulations are not a silver bullet that will immediately solve all AI-related issues. And the problem is much too complex to be solved by a single stakeholder. Regulators can set the process and expectations, but they cannot solve the underlying technical difficulties. Researchers have much work to do in investigating all the ways bias can creep into AI algorithms. Engineers carry the responsibility to build the necessary tools to not only detect bias, but to ensure <a href="https://david-haber.github.io/posts/ai-discipline/">AI systems work as intended</a>. Indeed, it will require the concerted effort by many, including society as a whole, to create truly trustworthy AI. I’m optimistic that we will rise to the challenge. And in the meantime, I recommend that you watch <a href="https://www.codedbias.com/">CodedBias</a>, in order to get a better understanding about the wider issues surrounding AI!</p>
<p><em>Thanks to <a href="https://www.linkedin.com/in/mateor/">Mateo</a>, <a href="https://www.linkedin.com/in/haberdavid/">David</a> and Ina for reading and commenting on drafts of this article. Image credits to <a href="https://unsplash.com/@niv">Niv Singer</a> and <a href="https://unsplash.com/">unsplash</a>. #safeai <a href="https://lakera.ai/">#LakeraAI</a></em></p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Translation and screenshot created on 23.4.2021, the results of the translation may have changed in the meantime. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>U.S. Food and Drug Administration. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Quote from Cathy O’Neil in the documentary <a href="https://www.codedbias.com/">CodedBias</a>. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://www.codedbias.com/sign">https://www.codedbias.com/sign</a> <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
    
        </div>
    </section>

    <footer class="post-full-footer">
      <section class="author-card">
        <img class="author-profile-image" src="https://mkraft89.github.io/image/cartoon_mk.png" alt="Author" />
        <section class="author-card-content">
            <h4 class="author-card-name"><a href="https://mkraft89.github.io/">Matthias Kraft</a></h4>
                <p>I’m a founder and CPO at Lakera AI, an engineer, and researcher who loves to solve technical, and business challenges and turn them into products.</p>
        </section>
      </section>
    </footer>
</article>
    
    
    

  </div>
</main>


<aside class="read-next outer">
  <div class="inner">
    <div class="read-next-feed">      
      

      
      
    </div>
  </div>
</aside>

<div class="floating-header">
  <div class="floating-header-logo">
    <a href="https://mkraft89.github.io/">
      
      <span></span>
    </a>
  </div>
  <span class="floating-header-divider">&mdash;</span>
  <div class="floating-header-title">Is AI making the same mistakes as us?</div>
  <div class="floating-header-share">
    <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
     <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/></svg>
    </div>
    
    <a class="floating-header-share-tw" href="https://twitter.com/share?text=Is%20AI%20making%20the%20same%20mistakes%20as%20us%3f&amp;url=https%3a%2f%2fmkraft89.github.io%2fis-ai-making-the-same-mistakes-as-us%2f"
          onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
      </a>
      <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fmkraft89.github.io%2fis-ai-making-the-same-mistakes-as-us%2f"
          onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
      </a>
  </div>

  <progress class="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>
</div>



<footer class="site-footer outer">
  <div class="site-footer-content inner">
    <section class="copyright" style="line-height: 1.3em;">
      <a href="/"></a>  <br>
      
    </section>
    <nav class="site-footer-nav">
        <a href="/">Latest Posts</a>
        
        
        <a href="https://github.com/mkraft89" target="_blank" rel="noopener">Github</a>
        <a href="https://www.linkedin.com/in/matthias-kraft-5b1229a1" target="_blank" rel="noopener">LinkedIn</a>
        
    </nav>  
  </div>
</footer>

</div>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script type="text/javascript" src="//code.jquery.com/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="https://mkraft89.github.io/js/jquery.fitvids.js"></script>

<script>hljs.initHighlightingOnLoad();</script>



    <script>





$(document).ready(function () {
    
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>
</body></html>
